{
  "v": 1,
  "id": "sha256:b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3",
  "content": "# AI Safety Summary\n\nBased on Jane Researcher's work:\n\n- Safety first approach recommended\n- 40% risk reduction with early implementation\n- Alignment, robustness, and transparency are key pillars\n",
  "meta": {
    "author": "Bob Writer",
    "created": "2025-01-07T10:00:00Z",
    "license": "AIBlocks-1.0",
    "lang": "en"
  },
  "refs": [
    {
      "type": "url",
      "url": "https://arxiv.org/abs/2301.00001",
      "title": "AI Safety Research Paper"
    }
  ],
  "parent": "sha256:a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2"
}
