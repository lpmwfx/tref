{
  "v": 1,
  "id": "sha256:a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2",
  "content": "# Understanding AI Safety\n\n## Introduction\n\nAI safety is critical for beneficial AI development.\n\n## Key Points\n\n1. Alignment with human values\n2. Robustness and reliability\n3. Transparency and interpretability\n\n## Conclusion\n\nSafety should be built in, not bolted on.\n",
  "meta": {
    "author": "Jane Researcher",
    "created": "2025-01-06T12:00:00Z",
    "modified": "2025-01-06T18:00:00Z",
    "license": "AIBlocks-1.0",
    "lang": "en"
  },
  "origin": {
    "url": "https://example.com/ai-safety",
    "title": "Understanding AI Safety"
  },
  "refs": [
    {
      "type": "url",
      "url": "https://arxiv.org/abs/2301.00001",
      "title": "AI Safety Research Paper",
      "accessed": "2025-01-06T10:00:00Z"
    },
    {
      "type": "archive",
      "snippet": "Key finding: safety measures reduce risk by 40% when implemented early in development.",
      "from": "https://oldsite.com/study",
      "archived": "2025-01-05T12:00:00Z"
    },
    {
      "type": "search",
      "query": "AI safety alignment research 2025",
      "engine": "google",
      "expect": "AI Safety Research Paper"
    },
    {
      "type": "hash",
      "alg": "sha256",
      "value": "abc123def456abc123def456abc123def456abc123def456abc123def456abc1",
      "of": "https://example.com/paper.pdf"
    }
  ]
}
